---
title: "Radio Resource Management for Cellular-Connected UAV: A Learning Approach"
collection: publications
#permalink: /publication/2022-RRM-TCom_MajorRevision
date: 2022-10-04
venue: 'IEEE Transactions on Communications (TCom)'
#paperurl: '/files/pdf/research/2021-QiRL-WCL.pdf'
link: 'https://arxiv.org/abs/2102.13222'
citation: '<strong>Major revision for IEEE Transactions on Communications (TCom), Oct. 2022.</strong>
<br>
<br>
Integrating unmanned aerial vehicles (UAVs) into existing cellular networks encounters lots of challenges, in which one of the most striking concerns is how to adopt UAVs into cellular networks with less adverse effects on ground user equipments (UEs). In this paper, a cellular-connected UAV network is focused, where multiple UAVs receive messages from terrestrial BSs in the down-link, while BSs are serving ground UEs in their cells. To enhance wireless transmission quality for UAVs while protecting ground UEs from being interfered by ground-to-air (G2A) transmissions, a joint time-frequency resource block (RB) and beamforming optimization problem minimizing UAV''s ergodic outage duration (EOD) is investigated. To solve the proposed radio resource management problem, a deep reinforcement learning (DRL)-aided solution is proposed, where deep double duelling Q network (D3QN) and twin delayed deep deterministic policy gradient (TD3) are invoked to deal with RB allocation in discrete action domain and beamforming design in continuous action regime, respectively. The hybrid D3QN-TD3 solution is applied to solve the outer MDP and the inner MDP interactively so that it can achieve the sub-optimal result for the considered optimization problem. Simulation results have illustrated the effectiveness of the proposed hybrid D3QN-TD3 algorithm, compared to exhaustive/random search based benchmarks.'
---